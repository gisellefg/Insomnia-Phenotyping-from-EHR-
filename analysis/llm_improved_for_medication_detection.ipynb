{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3aa3f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (2.0.44)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (2.9.11)\n",
      "Requirement already satisfied: ollama in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (21.0.0)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (2024.11.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from sqlalchemy) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from sqlalchemy) (4.15.0)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from ollama) (2.12.3)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from fastparquet) (2.3.3)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from fastparquet) (2.11.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from fastparquet) (2025.9.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from httpx>=0.27->ollama) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\gisel\\onedrive\\desktop\\insomnia phenotyping algorithm\\venv\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m pip install sqlalchemy psycopg2-binary ollama scikit-learn pyarrow fastparquet \n",
    "\n",
    "import os, json, re\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import ollama\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7abc1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to database\n",
    "PG_URL = \"postgresql+psycopg2://postgres:4030@localhost:5432/omop_sandbox\"\n",
    "engine = create_engine(PG_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f056abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we want to sample patients who appear in the gold standard and have at least one note\n",
    "#This is our gold standard subset for LLM inference\n",
    "\n",
    "patients = pd.read_sql(\"\"\"\n",
    "    SELECT DISTINCT c.subject_id\n",
    "    FROM mimic_omop.insomnia_cohort c\n",
    "    JOIN mimic_omop.notes_norm n\n",
    "      ON c.subject_id = n.subject_id\n",
    "    WHERE n.text IS NOT NULL AND LENGTH(n.text) > 50\n",
    "\"\"\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "231c10e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 10 gold-standard patients WITH notes:\n",
      "[18607084, 19940147, 10497294, 15090960, 15229355, 10240593, 19345921, 10325512, 18510965, 12544417, 12747844, 14210659, 16174060, 13689390, 19276983, 10451947, 13158370, 17887687, 13157375, 15203294]\n"
     ]
    }
   ],
   "source": [
    "sample_patients = patients[\"subject_id\"].sample(20, random_state=42)\n",
    "print(\"Using 10 gold-standard patients WITH notes:\")\n",
    "print(sample_patients.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f01d83cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Loaded 88 notes from 20 patients\n"
     ]
    }
   ],
   "source": [
    "#load all notes for 10 patients\n",
    "notes = pd.read_sql(f\"\"\"\n",
    "    SELECT subject_id, hadm_id, text AS note_text\n",
    "    FROM mimic_omop.notes_norm\n",
    "    WHERE subject_id IN ({\",\".join(map(str, sample_patients.tolist()))})\n",
    "      AND text IS NOT NULL AND LENGTH(text) > 50;\n",
    "\"\"\", engine)\n",
    "\n",
    "notes = notes.reset_index().rename(columns={\"index\": \"note_rowid\"})\n",
    "print(f\"ðŸ“„ Loaded {len(notes)} notes from {len(sample_patients)} patients\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07775e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gold standard\n",
    "gold = pd.read_sql(\"\"\"\n",
    "    SELECT subject_id, rule_a, rule_b, rule_c, any_rule AS any_gold\n",
    "    FROM mimic_omop.insomnia_cohort;\n",
    "\"\"\", engine)\n",
    "\n",
    "gold = gold.rename(columns={\n",
    "    \"rule_a\": \"rule_a_gold\",\n",
    "    \"rule_b\": \"rule_b_gold\",\n",
    "    \"rule_c\": \"rule_c_gold\"\n",
    "})\n",
    "\n",
    "gold = gold[gold[\"subject_id\"].isin(sample_patients)]\n",
    "for col in [\"rule_a_gold\", \"rule_b_gold\", \"rule_c_gold\", \"any_gold\"]:\n",
    "    gold[col] = gold[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62aac9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLEEP_TERMS = [\n",
    "    \"insomnia\", \"sleep onset\", \"sleep maintenance\", \"early awakening\",\n",
    "    \"trouble sleeping\", \"difficulty sleeping\", \"can't sleep\", \"cant sleep\",\n",
    "    \"sleep latency\", \"sleeplessness\", \"not sleeping\", \"poor sleep\",\n",
    "    \"restless sleep\", \"hard to fall asleep\", \"sleep problem\", \"sleep disturbance\"\n",
    "]\n",
    "\n",
    "IMPAIR_TERMS = [\n",
    "    \"fatigue\", \"tired\", \"daytime sleepiness\", \"somnolence\", \"malaise\",\n",
    "    \"irritable\", \"irritability\", \"poor concentration\", \"attention\",\n",
    "    \"memory\", \"impaired performance\", \"decreased motivation\",\n",
    "    \"errors\", \"accidents\", \"dissatisfaction with sleep\",\n",
    "    \"low energy\", \"hard to concentrate\", \"sleepy\", \"tiredness\"\n",
    "]\n",
    "\n",
    "PRIMARY_MED_TERMS = [\n",
    "    \"zolpidem\", \"ambien\", \"zaleplon\", \"sonata\", \"eszopiclone\", \"lunesta\",\n",
    "    \"temazepam\", \"restoril\", \"triazolam\", \"halcion\", \"ramelteon\", \"rozerem\",\n",
    "    \"suvorexant\", \"belsomra\", \"lemborexant\", \"dayvigo\"\n",
    "]\n",
    "\n",
    "SECONDARY_MED_TERMS = [\n",
    "    \"trazodone\", \"desyrel\", \"mirtazapine\", \"remeron\", \"melatonin\",\n",
    "    \"hydroxyzine\", \"vistaril\", \"atarax\", \"doxepin\", \"silenor\",\n",
    "    \"gabapentin\", \"neurontin\", \"quetiapine\", \"seroquel\",\n",
    "    \"olanzapine\", \"zyprexa\", \"clonazepam\", \"klonopin\",\n",
    "    \"lorazepam\", \"ativan\", \"diazepam\", \"valium\"\n",
    "]\n",
    "\n",
    "# Negation and historical context indicators\n",
    "NEGATION_TERMS = [\n",
    "    'deny', 'denies', 'denied', 'no longer', 'discontinued', \n",
    "    'stopped', 'not taking', \"wasn't taking\", 'refuses', 'allergic',\n",
    "    'no known', 'nka', 'nkda', 'without', 'never took'\n",
    "]\n",
    "\n",
    "HISTORICAL_TERMS = [\n",
    "    'history of', 'h/o', 'previously', 'past', 'prior', 'former',\n",
    "    'years ago', 'months ago', 'used to take'\n",
    "]\n",
    "\n",
    "PRESCRIPTION_INDICATORS = [\n",
    "    'continue', 'start', 'prescribe', 'prescribed', 'rx ', 'taking', \n",
    "    'dose', ' mg', 'qhs', 'qd', 'bid', 'tid', 'prn', 'daily',\n",
    "    'discharge medication', 'home medication', 'current medication'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c077a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#medication pre-detection\n",
    "def detect_medications(text: str):\n",
    "    \"\"\"Simple regex detection of medication mentions\"\"\"\n",
    "    t = text.lower()\n",
    "    is_primary = any(m in t for m in PRIMARY_MED_TERMS)\n",
    "    is_secondary = any(m in t for m in SECONDARY_MED_TERMS)\n",
    "    return is_primary, is_secondary\n",
    "\n",
    "def has_negation_context(text: str) -> bool:\n",
    "    \"\"\"Check if text contains negation indicators\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    return any(neg in text_lower for neg in NEGATION_TERMS)\n",
    "\n",
    "def has_historical_context(text: str) -> bool:\n",
    "    \"\"\"Check if text contains historical indicators\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    return any(hist in text_lower for hist in HISTORICAL_TERMS)\n",
    "\n",
    "def has_prescription_context(text: str) -> bool:\n",
    "    \"\"\"Check if text contains prescription indicators\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    return any(ind in text_lower for ind in PRESCRIPTION_INDICATORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b8de0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    \"\"\"Improved sentence splitting that preserves medication lists\"\"\"\n",
    "    # Protect common abbreviations\n",
    "    text = re.sub(r'(\\d+)\\.\\s*([A-Z])', r'\\1PERIODMARKER \\2', text)\n",
    "    text = re.sub(r'(Dr|Mr|Mrs|Ms|vs)\\.\\s', r'\\1PERIODMARKER ', text)\n",
    "    \n",
    "    sents = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    \n",
    "    # Restore periods\n",
    "    sents = [s.replace('PERIODMARKER', '.').strip()[:1500] \n",
    "             for s in sents if 5 < len(s) < 1500]\n",
    "    \n",
    "    return sents\n",
    "\n",
    "def is_candidate(sent):\n",
    "    \"\"\"Check if sentence contains relevant keywords\"\"\"\n",
    "    s = sent.lower()\n",
    "    return (\n",
    "        any(w in s for w in SLEEP_TERMS) or\n",
    "        any(w in s for w in IMPAIR_TERMS) or\n",
    "        any(w in s for w in PRIMARY_MED_TERMS) or\n",
    "        any(w in s for w in SECONDARY_MED_TERMS)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c83bc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Extracting candidate sentences...\n",
      "Extracted 250 candidate sentences\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Extracting candidate sentences...\")\n",
    "\n",
    "rows = []\n",
    "for _, r in notes.iterrows():\n",
    "    sents = split_sentences(r[\"note_text\"])\n",
    "    for i, s in enumerate(sents):\n",
    "        if is_candidate(s):\n",
    "            rows.append({\n",
    "                \"subject_id\": r[\"subject_id\"],\n",
    "                \"hadm_id\": r[\"hadm_id\"],\n",
    "                \"note_rowid\": r[\"note_rowid\"],\n",
    "                \"sent_id\": i,\n",
    "                \"text_span\": s\n",
    "            })\n",
    "\n",
    "cands = pd.DataFrame(rows)\n",
    "print(f\"Extracted {len(cands)} candidate sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d10ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#System prompt\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a clinical NLP system extracting evidence for insomnia phenotyping.\n",
    "\n",
    "PRIMARY insomnia medications (Rule B):\n",
    "zolpidem, zaleplon, eszopiclone, temazepam, triazolam,\n",
    "ramelteon, suvorexant, lemborexant.\n",
    "\n",
    "SECONDARY insomnia medications (Rule C):\n",
    "trazodone, mirtazapine, melatonin, hydroxyzine, doxepin,\n",
    "gabapentin, quetiapine, olanzapine, clonazepam, lorazepam, diazepam.\n",
    "\n",
    "IMPORTANT RULES:\n",
    "1. Carefully assess negation (e.g., \"denies\", \"discontinued\", \"no longer\")\n",
    "2. Distinguish current vs. historical mentions\n",
    "3. For medications: detect presence but respect negation and temporality\n",
    "4. For sleep difficulties: only mark if clearly current problem\n",
    "5. For daytime impairment: only mark if clearly current problem\n",
    "\n",
    "Return STRICT JSON:\n",
    "{\n",
    " \"asserts_sleep_difficulty\": bool,\n",
    " \"asserts_daytime_impairment\": bool,\n",
    " \"asserts_primary_med\": bool,\n",
    " \"asserts_secondary_med\": bool,\n",
    " \"negated\": bool,\n",
    " \"temporality\": \"current|historical|uncertain\"\n",
    "}\n",
    "\n",
    "Be conservative but accurate. When uncertain about temporality, mark as \"uncertain\".\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5671ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(text):\n",
    "    \"\"\"Extract JSON from LLM response\"\"\"\n",
    "    m = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        return {\"error\": \"no JSON\", \"raw\": text[:200]}\n",
    "    try:\n",
    "        return json.loads(m.group(0))\n",
    "    except:\n",
    "        return {\"error\": \"bad JSON\", \"raw\": m.group(0)}\n",
    "\n",
    "def classify_sentence_ollama(text: str):\n",
    "    \"\"\"\n",
    "    Classify sentence using LLM with smart medication override.\n",
    "      \n",
    "    Strategy:\n",
    "    1. Let LLM do full contextual analysis\n",
    "    2. Only override medication detection if:\n",
    "       - Medication found by regex\n",
    "       - LLM missed it\n",
    "       - Context suggests active prescription (not negated/historical)\n",
    "    \"\"\"\n",
    "    resp = ollama.chat(\n",
    "        model=\"llama3:8b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": SYSTEM_PROMPT + f'\\nSentence: \"{text}\"'}]\n",
    "    )\n",
    "    parsed = extract_json(resp[\"message\"][\"content\"])\n",
    "    \n",
    "    # Smart medication override - only when context is appropriate\n",
    "    prim_pre, sec_pre = detect_medications(text)\n",
    "    \n",
    "    likely_negated = has_negation_context(text)\n",
    "    likely_historical = has_historical_context(text)\n",
    "    likely_prescription = has_prescription_context(text)\n",
    "    \n",
    "    # Override primary medication detection if:\n",
    "    # 1. Regex found it\n",
    "    # 2. LLM missed it\n",
    "    # 3. Context suggests active prescription\n",
    "    # 4. NOT negated or historical\n",
    "    if prim_pre and not parsed.get(\"asserts_primary_med\", False):\n",
    "        if likely_prescription and not likely_negated and not likely_historical:\n",
    "            parsed[\"asserts_primary_med\"] = True\n",
    "            # If LLM didn't set temporality, default to current for prescriptions\n",
    "            if parsed.get(\"temporality\", \"uncertain\") == \"uncertain\":\n",
    "                parsed[\"temporality\"] = \"current\"\n",
    "    \n",
    "    # Same logic for secondary medications\n",
    "    if sec_pre and not parsed.get(\"asserts_secondary_med\", False):\n",
    "        if likely_prescription and not likely_negated and not likely_historical:\n",
    "            parsed[\"asserts_secondary_med\"] = True\n",
    "            if parsed.get(\"temporality\", \"uncertain\") == \"uncertain\":\n",
    "                parsed[\"temporality\"] = \"current\"\n",
    "    \n",
    "    # Ensure temporality is always set\n",
    "    if \"temporality\" not in parsed:\n",
    "        parsed[\"temporality\"] = \"uncertain\"\n",
    "    \n",
    "    return parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "688c9e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified 250 sentences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nCHECKPOINT_FILE = \"llm_imroved_progress.json\"\\n\\ndef save_checkpoint(results, idx):\\n    with open(CHECKPOINT_FILE, \"w\") as f:\\n        json.dump({\\n            \"results\": results,\\n            \"last_processed\": idx\\n        }, f)\\n\\ndef load_checkpoint():\\n    if os.path.exists(CHECKPOINT_FILE):\\n        with open(CHECKPOINT_FILE, \"r\") as f:\\n            return json.load(f)\\n    return {\"results\": [], \"last_processed\": -1}\\n\\n# Load past progress if exists\\ncheckpoint = load_checkpoint()\\nout = checkpoint[\"results\"]\\nstart_idx = checkpoint[\"last_processed\"] + 1\\n\\nprint(f\"â–¶ Resuming from sentence {start_idx} / {len(cands)}\")\\n\\ntry:\\n    for idx in range(start_idx, len(cands)):\\n        r = cands.iloc[idx]\\n\\n        # Run your LLM classifier\\n        y = classify_sentence_ollama(r[\"text_span\"])\\n\\n        # Append structured result\\n        out.append({**r.to_dict(), **y})\\n\\n        # Save checkpoint every 50 items\\n        if idx % 50 == 0:\\n            save_checkpoint(out, idx)\\n            print(f\"Checkpoint saved at {idx}\")\\n\\n            # Optional manual pause\\n            resp = input(\"Continue? (enter=yes, type \\'pause\\' to stop): \")\\n            if resp.strip().lower() == \"pause\":\\n                print(f\"â¸ Paused at {idx}. Run cell again to resume.\")\\n                break\\n\\nexcept KeyboardInterrupt:\\n    print(f\"\\nâ¹ Interrupted at {idx}, saving progressâ€¦\")\\n    save_checkpoint(out, idx)\\n\\nelse:\\n    print(\"âœ” All sentences classified!\")\\n    # Remove checkpoint to clean up\\n    if os.path.exists(CHECKPOINT_FILE):\\n        os.remove(CHECKPOINT_FILE)\\n\\n# Convert to dataframe at the end\\nev = pd.DataFrame(out)\\nprint(f\"Classified {len(ev)} sentences\")\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run LLM\n",
    "\n",
    "out = []\n",
    "for _, r in cands.iterrows():\n",
    "    y = classify_sentence_ollama(r[\"text_span\"])\n",
    "    out.append({**r, **y})\n",
    "\n",
    "ev = pd.DataFrame(out)\n",
    "print(f\"Classified {len(ev)} sentences\")\n",
    "'''\n",
    "\n",
    "\n",
    "CHECKPOINT_FILE = \"llm_imroved_progress.json\"\n",
    "\n",
    "def save_checkpoint(results, idx):\n",
    "    with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"results\": results,\n",
    "            \"last_processed\": idx\n",
    "        }, f)\n",
    "\n",
    "def load_checkpoint():\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {\"results\": [], \"last_processed\": -1}\n",
    "\n",
    "# Load past progress if exists\n",
    "checkpoint = load_checkpoint()\n",
    "out = checkpoint[\"results\"]\n",
    "start_idx = checkpoint[\"last_processed\"] + 1\n",
    "\n",
    "print(f\"â–¶ Resuming from sentence {start_idx} / {len(cands)}\")\n",
    "\n",
    "try:\n",
    "    for idx in range(start_idx, len(cands)):\n",
    "        r = cands.iloc[idx]\n",
    "\n",
    "        # Run your LLM classifier\n",
    "        y = classify_sentence_ollama(r[\"text_span\"])\n",
    "\n",
    "        # Append structured result\n",
    "        out.append({**r.to_dict(), **y})\n",
    "\n",
    "        # Save checkpoint every 50 items\n",
    "        if idx % 50 == 0:\n",
    "            save_checkpoint(out, idx)\n",
    "            print(f\"Checkpoint saved at {idx}\")\n",
    "\n",
    "            # Optional manual pause\n",
    "            resp = input(\"Continue? (enter=yes, type 'pause' to stop): \")\n",
    "            if resp.strip().lower() == \"pause\":\n",
    "                print(f\"â¸ Paused at {idx}. Run cell again to resume.\")\n",
    "                break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\nâ¹ Interrupted at {idx}, saving progressâ€¦\")\n",
    "    save_checkpoint(out, idx)\n",
    "\n",
    "else:\n",
    "    print(\"âœ” All sentences classified!\")\n",
    "    # Remove checkpoint to clean up\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        os.remove(CHECKPOINT_FILE)\n",
    "\n",
    "# Convert to dataframe at the end\n",
    "ev = pd.DataFrame(out)\n",
    "print(f\"Classified {len(ev)} sentences\")\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c58bb085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gisel\\AppData\\Local\\Temp\\ipykernel_11396\\2545120234.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ev[c] = ev[c].fillna(False).astype(bool)\n",
      "C:\\Users\\gisel\\AppData\\Local\\Temp\\ipykernel_11396\\2545120234.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ev[c] = ev[c].fillna(False).astype(bool)\n",
      "C:\\Users\\gisel\\AppData\\Local\\Temp\\ipykernel_11396\\2545120234.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ev[c] = ev[c].fillna(False).astype(bool)\n",
      "C:\\Users\\gisel\\AppData\\Local\\Temp\\ipykernel_11396\\2545120234.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ev[c] = ev[c].fillna(False).astype(bool)\n"
     ]
    }
   ],
   "source": [
    "# Ensure boolean columns are actually boolean\n",
    "bool_cols = [\n",
    "    \"asserts_sleep_difficulty\",\n",
    "    \"asserts_daytime_impairment\",\n",
    "    \"asserts_primary_med\",\n",
    "    \"negated\"\n",
    "]\n",
    "\n",
    "for c in bool_cols:\n",
    "    ev[c] = ev[c].fillna(False).astype(bool)\n",
    "\n",
    "# Ensure temporality is string (avoid float NaNs)\n",
    "ev[\"temporality\"] = ev[\"temporality\"].fillna(\"\").astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffb6d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Aggregating to patient level...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“Š Aggregating to patient level...\")\n",
    "\n",
    "ev[\"is_sleep\"] = ev[\"asserts_sleep_difficulty\"] & ~ev[\"negated\"] & (ev[\"temporality\"] == \"current\")\n",
    "ev[\"is_impair\"] = ev[\"asserts_daytime_impairment\"] & ~ev[\"negated\"] & (ev[\"temporality\"] == \"current\")\n",
    "ev[\"is_primary\"] = ev[\"asserts_primary_med\"] & ~ev[\"negated\"] & (ev[\"temporality\"] == \"current\")\n",
    "ev[\"is_secondary\"] = ev[\"asserts_secondary_med\"] & ~ev[\"negated\"] & (ev[\"temporality\"] == \"current\")\n",
    "\n",
    "agg = ev.groupby(\"subject_id\").agg({\n",
    "    \"is_sleep\": \"max\",\n",
    "    \"is_impair\": \"max\",\n",
    "    \"is_primary\": \"max\",\n",
    "    \"is_secondary\": \"max\"\n",
    "}).reset_index()\n",
    "\n",
    "agg[\"rule_a_text\"] = (agg[\"is_sleep\"] & agg[\"is_impair\"]).astype(int)\n",
    "agg[\"rule_b_text\"] = agg[\"is_primary\"].astype(int)\n",
    "agg[\"rule_c_text\"] = agg[\"is_secondary\"].astype(int)\n",
    "agg[\"any_text\"] = agg[[\"rule_a_text\", \"rule_b_text\", \"rule_c_text\"]].any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d010c46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EVALUATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "=== Rule A (Symptoms) ===\n",
      "Confusion Matrix:\n",
      "[[9 1]\n",
      " [7 3]]\n",
      "Precision: 0.750\n",
      "Recall:    0.300\n",
      "F1 Score:  0.429\n",
      "\n",
      "=== Rule B (Primary Meds) ===\n",
      "Confusion Matrix:\n",
      "[[ 3  0]\n",
      " [14  3]]\n",
      "Precision: 1.000\n",
      "Recall:    0.176\n",
      "F1 Score:  0.300\n",
      "\n",
      "=== Rule C (Secondary Meds) ===\n",
      "Confusion Matrix:\n",
      "[[ 2  1]\n",
      " [ 4 13]]\n",
      "Precision: 0.929\n",
      "Recall:    0.765\n",
      "F1 Score:  0.839\n",
      "\n",
      "=== Any Rule (Insomnia) ===\n",
      "Confusion Matrix:\n",
      "[[ 0  0]\n",
      " [ 6 14]]\n",
      "Precision: 1.000\n",
      "Recall:    0.700\n",
      "F1 Score:  0.824\n"
     ]
    }
   ],
   "source": [
    "df = gold.merge(agg, on=\"subject_id\", how=\"left\").fillna(0)\n",
    "\n",
    "for col in [\"rule_a_text\", \"rule_b_text\", \"rule_c_text\", \"any_text\"]:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def evaluate(true, pred, label):\n",
    "    print(f\"\\n=== {label} ===\")\n",
    "    cm = confusion_matrix(true, pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    prec = precision_score(true, pred, zero_division=0)\n",
    "    rec = recall_score(true, pred, zero_division=0)\n",
    "    f1 = f1_score(true, pred, zero_division=0)\n",
    "    \n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall:    {rec:.3f}\")\n",
    "    print(f\"F1 Score:  {f1:.3f}\")\n",
    "    \n",
    "    return {\"precision\": prec, \"recall\": rec, \"f1\": f1}\n",
    "\n",
    "results = {}\n",
    "results[\"Rule A (Symptoms)\"] = evaluate(df[\"rule_a_gold\"], df[\"rule_a_text\"], \"Rule A (Symptoms)\")\n",
    "results[\"Rule B (Primary Meds)\"] = evaluate(df[\"rule_b_gold\"], df[\"rule_b_text\"], \"Rule B (Primary Meds)\")\n",
    "results[\"Rule C (Secondary Meds)\"] = evaluate(df[\"rule_c_gold\"], df[\"rule_c_text\"], \"Rule C (Secondary Meds)\")\n",
    "results[\"Any Rule\"] = evaluate(df[\"any_gold\"], df[\"any_text\"], \"Any Rule (Insomnia)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3f33955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR ANALYSIS\n",
      "FALSE NEGATIVES: 6 patients\n",
      "   Patient IDs: [12747844, 13158370, 16174060, 17887687, 18510965, 19345921]\n",
      "\n",
      "   Patient 12747844:\n",
      "     Gold: Rule A=1, Rule B=1, Rule C=1\n",
      "     LLM found 4 candidate sentences:\n",
      "       - Sleep difficulty: 0 mentions\n",
      "       - Daytime impairment: 1 mentions\n",
      "       - Primary meds: 0 mentions\n",
      "       - Secondary meds: 1 mentions\n",
      "\n",
      "   Patient 13158370:\n",
      "     Gold: Rule A=1, Rule B=0, Rule C=0\n",
      "     LLM found 10 candidate sentences:\n",
      "       - Sleep difficulty: 0 mentions\n",
      "       - Daytime impairment: 0 mentions\n",
      "       - Primary meds: 0 mentions\n",
      "       - Secondary meds: 1 mentions\n",
      "\n",
      "   Patient 16174060:\n",
      "     Gold: Rule A=1, Rule B=0, Rule C=0\n",
      "     LLM found 4 candidate sentences:\n",
      "       - Sleep difficulty: 1 mentions\n",
      "       - Daytime impairment: 0 mentions\n",
      "       - Primary meds: 0 mentions\n",
      "       - Secondary meds: 1 mentions\n",
      "\n",
      "   Patient 17887687:\n",
      "     Gold: Rule A=1, Rule B=1, Rule C=1\n",
      " NO candidates extracted!\n",
      "\n",
      "   Patient 18510965:\n",
      "     Gold: Rule A=0, Rule B=1, Rule C=1\n",
      "     LLM found 1 candidate sentences:\n",
      "       - Sleep difficulty: 1 mentions\n",
      "       - Daytime impairment: 0 mentions\n",
      "       - Primary meds: 0 mentions\n",
      "       - Secondary meds: False mentions\n",
      "\n",
      "   Patient 19345921:\n",
      "     Gold: Rule A=1, Rule B=1, Rule C=1\n",
      " NO candidates extracted!\n",
      "FALSE POSITIVES: 0 patients\n",
      "   Patient IDs: []\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "\n",
    "print(\"ERROR ANALYSIS\")\n",
    "\n",
    "\n",
    "# False Negatives\n",
    "fn = df[(df[\"any_gold\"] == 1) & (df[\"any_text\"] == 0)]\n",
    "print(f\"FALSE NEGATIVES: {len(fn)} patients\")\n",
    "print(f\"   Patient IDs: {fn['subject_id'].tolist()}\")\n",
    "\n",
    "for _, patient in fn.iterrows():\n",
    "    pid = patient[\"subject_id\"]\n",
    "    print(f\"\\n   Patient {pid}:\")\n",
    "    print(f\"     Gold: Rule A={patient['rule_a_gold']}, Rule B={patient['rule_b_gold']}, Rule C={patient['rule_c_gold']}\")\n",
    "    \n",
    "    patient_ev = ev[ev[\"subject_id\"] == pid]\n",
    "    if len(patient_ev) > 0:\n",
    "        print(f\"     LLM found {len(patient_ev)} candidate sentences:\")\n",
    "        print(f\"       - Sleep difficulty: {patient_ev['asserts_sleep_difficulty'].sum()} mentions\")\n",
    "        print(f\"       - Daytime impairment: {patient_ev['asserts_daytime_impairment'].sum()} mentions\")\n",
    "        print(f\"       - Primary meds: {patient_ev['asserts_primary_med'].sum()} mentions\")\n",
    "        print(f\"       - Secondary meds: {patient_ev['asserts_secondary_med'].sum()} mentions\")\n",
    "    else:\n",
    "        print(f\" NO candidates extracted!\")\n",
    "\n",
    "# False Positives\n",
    "fp = df[(df[\"any_gold\"] == 0) & (df[\"any_text\"] == 1)]\n",
    "print(f\"FALSE POSITIVES: {len(fp)} patients\")\n",
    "print(f\"   Patient IDs: {fp['subject_id'].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b627340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARISON TABLE\n",
      "======================================================================\n",
      "\n",
      "             Rule  Gold +  LLM +  TP  FN  FP  Precision  Recall    F1\n",
      "      A: Symptoms      10      4   3   7   1      0.750   0.300 0.429\n",
      "  B: Primary Meds      17      3   3  14   0      1.000   0.176 0.300\n",
      "C: Secondary Meds      17     14  13   4   1      0.929   0.765 0.839\n",
      "         Any Rule      20     14  14   6   0      1.000   0.700 0.824\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON TABLE\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Rule': ['A: Symptoms', 'B: Primary Meds', 'C: Secondary Meds', 'Any Rule'],\n",
    "    'Gold +': [\n",
    "        df['rule_a_gold'].sum(),\n",
    "        df['rule_b_gold'].sum(),\n",
    "        df['rule_c_gold'].sum(),\n",
    "        df['any_gold'].sum()\n",
    "    ],\n",
    "    'LLM +': [\n",
    "        df['rule_a_text'].sum(),\n",
    "        df['rule_b_text'].sum(),\n",
    "        df['rule_c_text'].sum(),\n",
    "        df['any_text'].sum()\n",
    "    ],\n",
    "    'TP': [\n",
    "        ((df['rule_a_gold']==1) & (df['rule_a_text']==1)).sum(),\n",
    "        ((df['rule_b_gold']==1) & (df['rule_b_text']==1)).sum(),\n",
    "        ((df['rule_c_gold']==1) & (df['rule_c_text']==1)).sum(),\n",
    "        ((df['any_gold']==1) & (df['any_text']==1)).sum()\n",
    "    ],\n",
    "    'FN': [\n",
    "        ((df['rule_a_gold']==1) & (df['rule_a_text']==0)).sum(),\n",
    "        ((df['rule_b_gold']==1) & (df['rule_b_text']==0)).sum(),\n",
    "        ((df['rule_c_gold']==1) & (df['rule_c_text']==0)).sum(),\n",
    "        ((df['any_gold']==1) & (df['any_text']==0)).sum()\n",
    "    ],\n",
    "    'FP': [\n",
    "        ((df['rule_a_gold']==0) & (df['rule_a_text']==1)).sum(),\n",
    "        ((df['rule_b_gold']==0) & (df['rule_b_text']==1)).sum(),\n",
    "        ((df['rule_c_gold']==0) & (df['rule_c_text']==1)).sum(),\n",
    "        ((df['any_gold']==0) & (df['any_text']==1)).sum()\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison['Precision'] = comparison['TP'] / (comparison['TP'] + comparison['FP'])\n",
    "comparison['Recall'] = comparison['TP'] / comparison['Gold +']\n",
    "comparison['F1'] = 2 * (comparison['Precision'] * comparison['Recall']) / (comparison['Precision'] + comparison['Recall'])\n",
    "\n",
    "print(comparison.round(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c3d072b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FALSE NEGATIVE ANALYSIS (6 patients)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Patient 12747844:\n",
      "  Gold: Rule A=1, Rule B=1, Rule C=1\n",
      "  LLM found 4 candidate sentences\n",
      "  Sleep mentions: 0\n",
      "  Impairment mentions: 1\n",
      "  Primary meds: 0\n",
      "  Secondary meds: 1\n",
      "  âš ï¸  Found 'mirtazapine' in note: ...is management of \n",
      "variceal monitoring\n",
      "[ ] If ___ has persistently poor appetite, consider starting \n",
      "mirtazapine QHS for appetite stimulation\n",
      "[ ] Please titrate blood pressure medications as needed. \n",
      "\n",
      "...\n",
      "\n",
      "Patient 13158370:\n",
      "  Gold: Rule A=1, Rule B=0, Rule C=0\n",
      "  LLM found 10 candidate sentences\n",
      "  Sleep mentions: 0\n",
      "  Impairment mentions: 0\n",
      "  Primary meds: 0\n",
      "  Secondary meds: 1\n",
      "  âš ï¸  Found 'ambien' in note: ...lving the left frontal lobe as before.\n",
      "\n",
      "The basal cisterns, especially the quadrigeminal plate and \n",
      "ambient cisterns are better visualized suggestive of improved \n",
      "edema.\n",
      "\n",
      "Tiny amounts of pneumocephalu...\n",
      "  âš ï¸  Found 'hydroxyzine' in note: ...BISMOL) 262 MG chewable tablet \n",
      "clobetasol (TEMOVATE) 0.05 % cream \n",
      "camphor-menthol (SARNA) lotion \n",
      "hydrOXYzine (ATARAX) 25 MG tablet \n",
      "cholecalciferol (VITAMIN D) 1000 UNITS capsule \n",
      "nitroGLYCERIN (NI...\n",
      "  âš ï¸  Found 'atarax' in note: ...G chewable tablet \n",
      "clobetasol (TEMOVATE) 0.05 % cream \n",
      "camphor-menthol (SARNA) lotion \n",
      "hydrOXYzine (ATARAX) 25 MG tablet \n",
      "cholecalciferol (VITAMIN D) 1000 UNITS capsule \n",
      "nitroGLYCERIN (NITROSTAT) 0.4 ...\n",
      "\n",
      "Patient 16174060:\n",
      "  Gold: Rule A=1, Rule B=0, Rule C=0\n",
      "  LLM found 4 candidate sentences\n",
      "  Sleep mentions: 1\n",
      "  Impairment mentions: 0\n",
      "  Primary meds: 0\n",
      "  Secondary meds: 1\n",
      "  âš ï¸  Found 'ativan' in note: ...ent declined initiation of psychotropic medications during \n",
      "his hospitalization. He was offered prn Ativan, which he did not \n",
      "require. \n",
      "- Mr. ___ maintained excellent behavioral control in the \n",
      "milieu...\n",
      "\n",
      "Patient 17887687:\n",
      "  Gold: Rule A=1, Rule B=1, Rule C=1\n",
      "  âš ï¸  NO candidates extracted - check vocabulary coverage!\n",
      "\n",
      "Patient 18510965:\n",
      "  Gold: Rule A=0, Rule B=1, Rule C=1\n",
      "  LLM found 1 candidate sentences\n",
      "  Sleep mentions: 1\n",
      "  Impairment mentions: 0\n",
      "  Primary meds: 0\n",
      "  Secondary meds: False\n",
      "\n",
      "Patient 19345921:\n",
      "  Gold: Rule A=1, Rule B=1, Rule C=1\n",
      "  âš ï¸  NO candidates extracted - check vocabulary coverage!\n"
     ]
    }
   ],
   "source": [
    "#Detailed error analysis\n",
    "# Detailed false negative analysis\n",
    "def analyze_false_negatives(df, ev, notes):\n",
    "    \"\"\"Analyze why patients were missed\"\"\"\n",
    "    fn = df[(df[\"any_gold\"]==1) & (df[\"any_text\"]==0)]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FALSE NEGATIVE ANALYSIS ({len(fn)} patients)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    for _, patient in fn.iterrows():\n",
    "        pid = patient[\"subject_id\"]\n",
    "        print(f\"\\nPatient {pid}:\")\n",
    "        print(f\"  Gold: Rule A={patient['rule_a_gold']}, Rule B={patient['rule_b_gold']}, Rule C={patient['rule_c_gold']}\")\n",
    "        \n",
    "        # Check what LLM extracted\n",
    "        patient_ev = ev[ev[\"subject_id\"]==pid]\n",
    "        if len(patient_ev) > 0:\n",
    "            print(f\"  LLM found {len(patient_ev)} candidate sentences\")\n",
    "            print(f\"  Sleep mentions: {patient_ev['asserts_sleep_difficulty'].sum()}\")\n",
    "            print(f\"  Impairment mentions: {patient_ev['asserts_daytime_impairment'].sum()}\")\n",
    "            print(f\"  Primary meds: {patient_ev['asserts_primary_med'].sum()}\")\n",
    "            print(f\"  Secondary meds: {patient_ev['asserts_secondary_med'].sum()}\")\n",
    "            \n",
    "            # Show examples where medications might be\n",
    "            patient_notes = notes[notes[\"subject_id\"]==pid]\n",
    "            for term in PRIMARY_MED_TERMS + SECONDARY_MED_TERMS:\n",
    "                for _, note in patient_notes.iterrows():\n",
    "                    if term.lower() in note[\"note_text\"].lower():\n",
    "                        # Find context\n",
    "                        idx = note[\"note_text\"].lower().find(term.lower())\n",
    "                        context = note[\"note_text\"][max(0,idx-100):idx+100]\n",
    "                        print(f\"  âš ï¸  Found '{term}' in note: ...{context}...\")\n",
    "                        break\n",
    "        else:\n",
    "            print(f\"  âš ï¸  NO candidates extracted - check vocabulary coverage!\")\n",
    "\n",
    "analyze_false_negatives(df, ev, notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8baa8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence(row):\n",
    "    \"\"\"Estimate confidence in classification\"\"\"\n",
    "    confidence = 1.0\n",
    "    \n",
    "    # Reduce confidence if negated\n",
    "    if row[\"negated\"]:\n",
    "        confidence *= 0.3\n",
    "    \n",
    "    # Reduce confidence if uncertain temporality\n",
    "    if row[\"temporality\"] == \"uncertain\":\n",
    "        confidence *= 0.7\n",
    "    elif row[\"temporality\"] == \"historical\":\n",
    "        confidence *= 0.5\n",
    "    \n",
    "    return confidence\n",
    "\n",
    "ev[\"confidence\"] = ev.apply(calculate_confidence, axis=1)\n",
    "\n",
    "# Filter by confidence threshold\n",
    "threshold = 0.5\n",
    "ev_filtered = ev[ev[\"confidence\"] >= threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b53c5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Metric  Gold_Positive  LLM_Positive  True_Positives  \\\n",
      "0        Rule A (Symptoms)             10             4               3   \n",
      "1    Rule B (Primary Meds)             17             3               3   \n",
      "2  Rule C (Secondary Meds)             17            14              13   \n",
      "3                 Any Rule             20            14              14   \n",
      "\n",
      "   False_Negatives  False_Positives  Precision  Recall     F1  \n",
      "0                7                1      0.750   0.300  0.429  \n",
      "1               14                0      1.000   0.176  0.300  \n",
      "2                4                1      0.929   0.765  0.839  \n",
      "3                6                0      1.000   0.700  0.824  \n"
     ]
    }
   ],
   "source": [
    "def create_comparison_table(df):\n",
    "    \"\"\"Create detailed comparison table\"\"\"\n",
    "    comparison = pd.DataFrame({\n",
    "        'Metric': ['Rule A (Symptoms)', 'Rule B (Primary Meds)', \n",
    "                   'Rule C (Secondary Meds)', 'Any Rule'],\n",
    "        'Gold_Positive': [\n",
    "            df['rule_a_gold'].sum(),\n",
    "            df['rule_b_gold'].sum(),\n",
    "            df['rule_c_gold'].sum(),\n",
    "            df['any_gold'].sum()\n",
    "        ],\n",
    "        'LLM_Positive': [\n",
    "            df['rule_a_text'].sum(),\n",
    "            df['rule_b_text'].sum(),\n",
    "            df['rule_c_text'].sum(),\n",
    "            df['any_text'].sum()\n",
    "        ],\n",
    "        'True_Positives': [\n",
    "            ((df['rule_a_gold']==1) & (df['rule_a_text']==1)).sum(),\n",
    "            ((df['rule_b_gold']==1) & (df['rule_b_text']==1)).sum(),\n",
    "            ((df['rule_c_gold']==1) & (df['rule_c_text']==1)).sum(),\n",
    "            ((df['any_gold']==1) & (df['any_text']==1)).sum()\n",
    "        ],\n",
    "        'False_Negatives': [\n",
    "            ((df['rule_a_gold']==1) & (df['rule_a_text']==0)).sum(),\n",
    "            ((df['rule_b_gold']==1) & (df['rule_b_text']==0)).sum(),\n",
    "            ((df['rule_c_gold']==1) & (df['rule_c_text']==0)).sum(),\n",
    "            ((df['any_gold']==1) & (df['any_text']==0)).sum()\n",
    "        ],\n",
    "        'False_Positives': [\n",
    "            ((df['rule_a_gold']==0) & (df['rule_a_text']==1)).sum(),\n",
    "            ((df['rule_b_gold']==0) & (df['rule_b_text']==1)).sum(),\n",
    "            ((df['rule_c_gold']==0) & (df['rule_c_text']==1)).sum(),\n",
    "            ((df['any_gold']==0) & (df['any_text']==1)).sum()\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    comparison['Precision'] = comparison['True_Positives'] / comparison['LLM_Positive']\n",
    "    comparison['Recall'] = comparison['True_Positives'] / comparison['Gold_Positive']\n",
    "    comparison['F1'] = 2 * (comparison['Precision'] * comparison['Recall']) / (comparison['Precision'] + comparison['Recall'])\n",
    "    \n",
    "    return comparison.round(3)\n",
    "\n",
    "print(create_comparison_table(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d439504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Saving results...\n",
      "âœ“ All results saved!\n",
      "\n",
      "Files created:\n",
      "  - notes_sample_improved.csv\n",
      "  - ev_sentence_level_improved.csv\n",
      "  - agg_patient_level_improved.csv\n",
      "  - df_evaluation_improved.csv\n",
      "  - false_negatives_improved.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ’¾ Saving results...\")\n",
    "\n",
    "notes.to_csv(\"notes_sample_improved.csv\", index=False)\n",
    "ev.to_csv(\"ev_sentence_level_improved.csv\", index=False)\n",
    "agg.to_csv(\"agg_patient_level_improved.csv\", index=False)\n",
    "df.to_csv(\"df_evaluation_improved.csv\", index=False)\n",
    "\n",
    "false_neg = df[(df[\"any_gold\"]==1) & (df[\"any_text\"]==0)]\n",
    "false_pos = df[(df[\"any_gold\"]==0) & (df[\"any_text\"]==1)]\n",
    "\n",
    "false_neg.to_csv(\"false_negatives_improved.csv\", index=False)\n",
    "false_pos.to_csv(\"false_positives_improved.csv\", index=False)\n",
    "\n",
    "print(\"âœ“ All results saved!\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - notes_sample_improved.csv\")\n",
    "print(\"  - ev_sentence_level_improved.csv\")\n",
    "print(\"  - agg_patient_level_improved.csv\")\n",
    "print(\"  - df_evaluation_improved.csv\")\n",
    "print(\"  - false_negatives_improved.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
